{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgF-ZjLIytyY"
      },
      "outputs": [],
      "source": [
        "# Dependencies\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "import scipy.stats as ss\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "import keras\n",
        "import tensorflow\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Activation, Dense, Flatten, LeakyReLU, Dropout\n",
        "from keras import backend\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import get_custom_objects\n",
        "from keras import backend as K\n",
        "from keras.activations import elu, sigmoid\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJ4qftxtRdpV"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.set_floatx('float32')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mQvv6Kz3y2tn"
      },
      "outputs": [],
      "source": [
        "N = norm.cdf\n",
        "def BS_CALL(S, K, T, r, q , sigma):\n",
        "    d1 = (np.log(S/K) + (r + sigma**2/2)*T) / (sigma*np.sqrt(T))\n",
        "    d2 = d1 - sigma * np.sqrt(T)\n",
        "    return S*(math.exp(-q*T))* N(d1) - K * np.exp(-r*T)* N(d2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYjU5sCty4h1"
      },
      "outputs": [],
      "source": [
        "price = np.random.uniform(10, 20, 300000)\n",
        "strike = np.random.uniform(10, 20, 300000)\n",
        "time = np.random.uniform(0.1, 3, 300000)\n",
        "intrest = np.random.uniform(0.01, 0.03, 300000)\n",
        "divident = np.random.uniform(0, 0.03, 300000)\n",
        "volatility = np.random.uniform(0.05, 0.3, 300000)\n",
        "call = np.zeros(300000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScA8_Cumy6PL"
      },
      "outputs": [],
      "source": [
        "for i in range(0,300000):\n",
        "  call[i] = BS_CALL(price[i],strike[i],time[i],intrest[i],divident[i],volatility[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ESJyYrxy8bX"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6f4ZqNG-y-rq"
      },
      "outputs": [],
      "source": [
        "df['Stock'] = price.tolist()\n",
        "df['Strike'] = strike.tolist()\n",
        "df['Time'] = time.tolist()\n",
        "df['Intrest'] = intrest.tolist()\n",
        "df['Divident'] = divident.tolist()\n",
        "df['Volatility'] = volatility.tolist()\n",
        "df['Call'] = call.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices(({\n",
        "    'Stock': df['Stock'].values,\n",
        "    'Strike': df['Strike'].values,\n",
        "    'Time': df['Time'].values.astype(np.float32),  # Make sure Time is a float32 tensor for gradient\n",
        "    'Intrest': df['Intrest'].values,\n",
        "    'Divident': df['Divident'].values,\n",
        "    'Volatility': df['Volatility'].values\n",
        "}, df['Call'].values))"
      ],
      "metadata": {
        "id": "lizckbKnFCYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovMIWIyLzAkp"
      },
      "outputs": [],
      "source": [
        "df_filtered = df[df['Call'] <= 10]\n",
        "df_filtered = df_filtered[df_filtered['Call'] >= 0.001]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8ynd64IzCXX"
      },
      "outputs": [],
      "source": [
        "df_filtered['Stock'] = df_filtered['Stock'].div(df_filtered.Strike)\n",
        "df_filtered['Call'] = df_filtered['Call'].div(df_filtered.Strike)\n",
        "MinCall = df_filtered.loc[df_filtered[\"Call\"].idxmin()].Call\n",
        "df_filtered['Strike'] = 1\n",
        "Strike = df_filtered.Strike.values\n",
        "df_filtered = df_filtered.drop('Strike', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5POFFP1MzFev"
      },
      "outputs": [],
      "source": [
        "df_filtered['Call'] = df_filtered['Call'] - 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzSVrbM8zHZE"
      },
      "outputs": [],
      "source": [
        "prices = df_filtered.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w93eU9Z9zI20"
      },
      "outputs": [],
      "source": [
        "X = prices[:,:5]\n",
        "y = prices[:,5:6]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7fnSg7fHzLB-"
      },
      "outputs": [],
      "source": [
        "def custom_activation(x):\n",
        "    return (K.softplus(x)-0.5)\n",
        "\n",
        "get_custom_objects().update({'custom_activation': Activation(custom_activation)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0HlKZUl9zNV9"
      },
      "outputs": [],
      "source": [
        "def MELU(z):\n",
        "  cond = K.greater(z, 0)\n",
        "  return K.switch(cond, (((0.5*(K.pow((z),2)))+(0.02*(z)))/((z)+0.040816326)),0.49*(K.exp(z)-1))\n",
        "\n",
        "get_custom_objects().update({'MELU': Activation(MELU)})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SENiStZ6VM-1",
        "outputId": "be541d0d-d975-4de5-d11c-0b35074c6d4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/compat/v2_compat.py:108: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfe = tf.compat.v1.estimator.eager\n",
        "tf.enable_eager_execution()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "jFz0nc07N8T1",
        "outputId": "e2bda149-20a2-4d72-fbf5-33c1a69c95a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "module 'tensorflow_estimator.python.estimator.api._v1.estimator' has no attribute 'eager'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-56df57c24f2c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtfe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_eager_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/lazy_loader.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/module_wrapper.py\u001b[0m in \u001b[0;36m_getattr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \"\"\"\n\u001b[1;32m    231\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m       \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfmw_wrapped_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0;31m# Placeholder for Google-internal contrib error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_estimator.python.estimator.api._v1.estimator' has no attribute 'eager'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-M9MfZxWzQNR"
      },
      "outputs": [],
      "source": [
        "from pandas.core.arrays.arrow.array import Any\n",
        "nodes = 128\n",
        "def make_model():\n",
        "  net = tf.keras.Sequential()\n",
        "\n",
        "# Layer 1\n",
        "  net.add(tf.keras.layers.Dense(nodes , input_shape=(5,)))\n",
        "  net.add(tf.keras.layers.Activation(LeakyReLU(1.0)))\n",
        "\n",
        "# Layer 2\n",
        "  net.add(tf.keras.layers.Dense(nodes))\n",
        "  net.add(tf.keras.layers.Activation (MELU))\n",
        "\n",
        "# Layer 3\n",
        "  net.add(tf.keras.layers.Dense(nodes))\n",
        "  net.add(tf.keras.layers.Activation (MELU))\n",
        "\n",
        "# Layer 4 - Output Layer\n",
        "  net.add(tf.keras.layers.Dense(1))\n",
        "  net.add(tf.keras.layers.Activation(custom_activation))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(pred, actual):\n",
        "    return tf.reduce_mean(tf.square(tf.subtract(pred, actual)))\n"
      ],
      "metadata": {
        "id": "FokZXVhBWQUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient(model, pred, actual):\n",
        "    \"\"\"compute gradients with given noise and input\"\"\"\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = compute_loss(pred, actual)\n",
        "    grads = tape.gradient(loss, model.variables)\n",
        "    return grads, loss"
      ],
      "metadata": {
        "id": "wKCbsxnlWR_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_gradients(optimizer, grads, model_vars):\n",
        "    optimizer.apply_gradients(zip(grads, model_vars))"
      ],
      "metadata": {
        "id": "BHwK1lcpWXID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = make_model()\n",
        "optimizer = tf.train.AdamOptimizer(1e-4)"
      ],
      "metadata": {
        "id": "B5b7-y1sWcjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eyj3gG7OTU1R"
      },
      "outputs": [],
      "source": [
        "# def custom_loss_pass(model, x_tensor):\n",
        "#     def custom_loss(y_true,y_pred):\n",
        "#         with tf.GradientTape() as t:\n",
        "#             t.watch(x_tensor)\n",
        "#             output = model(x_tensor)\n",
        "#         DyDX = t.gradient(output, x_tensor)\n",
        "#         dy_t = DyDX[:, 5:6]\n",
        "#         R_pred=dy_t\n",
        "#         # loss_data = tf.reduce_mean(tf.square(yTrue - yPred), axis=-1)\n",
        "#         loss_PDE = tf.reduce_mean(tf.square(R_pred))\n",
        "#         return loss_PDE\n",
        "#     return custom_loss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def custom_penalty(x, lambda_val):\n",
        "#     return tf.where(x >= 0, lambda_val * tf.pow(x, 4), tf.zeros_like(x))\n"
      ],
      "metadata": {
        "id": "cqW6leSL-PAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assume a simple model\n",
        "# model = tf.keras.Sequential([...])\n",
        "# # Assume lambda values for each term\n",
        "# lambda_1 = 0.01  # example value for lambda_1\n",
        "# lambda_2 = 0.01  # example value for lambda_2\n",
        "# lambda_3 = 0.01  # example value for lambda_3\n",
        "# optimizer='adam'\n",
        "# # Define the constant K\n",
        "# K = tf.constant([...], dtype=tf.float32)\n",
        "\n",
        "# # Training loop\n",
        "# for epoch in range(15):\n",
        "#     for step, (X_train,y_train) in enumerate(train_dataset):\n",
        "#         # T is part of x_batch_train and is a trainable variable\n",
        "#         with tf.GradientTape(persistent=True) as tape:\n",
        "#             # Ensure the tape is watching the trainable variables\n",
        "#             tape.watch(model.trainable_variables)\n",
        "\n",
        "#             # Forward pass: compute predictions\n",
        "#             predictions = model(X_train)\n",
        "#             # Compute the base loss (MSE)\n",
        "#             base_loss = tf.keras.losses.mean_squared_error(y_train, predictions)\n",
        "\n",
        "#             # Compute the derivative with respect to T\n",
        "#             grads_wrt_T = tape.gradient(predictions, [T])[0]\n",
        "\n",
        "#             # Apply the penalty functions\n",
        "#             penalty_2 = custom_penalty(grads_wrt_T, lambda_2)\n",
        "\n",
        "#             # Since the second derivative of C_ANN with respect to K is zero (K is a constant),\n",
        "#             # penalty_1 will be zero and does not need to be computed.\n",
        "#             # penalty_3 is not applied because there is no gradient with respect to a constant K.\n",
        "\n",
        "#             # Sum up penalties\n",
        "#             penalties = tf.reduce_sum(penalty_2)\n",
        "\n",
        "#             # Total loss is base loss plus penalties\n",
        "#             total_loss = base_loss + penalties\n",
        "\n",
        "#         # Compute gradients of total loss with respect to model's trainable weights\n",
        "#         gradients = tape.gradient(total_loss, model.trainable_variables)\n",
        "\n",
        "#         # Update weights\n",
        "#         optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "# # Clean up the persistent tape\n",
        "# del tape\n"
      ],
      "metadata": {
        "id": "SrFJDKjR9fq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batched_dataset = dataset.batch(64)"
      ],
      "metadata": {
        "id": "XAHY5m4AFXuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9Qx6BgxzQ_S"
      },
      "outputs": [],
      "source": [
        "model.compile(loss= tf.keras.losses.MeanSquaredError(),\n",
        "  optimizer='adam',)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for features, _ in batched_dataset:\n",
        "    with tf.GradientTape() as tape:\n",
        "        # Extract the 'Time' tensor and ensure it's being watched by the gradient tape\n",
        "        time_tensor = features['Time']\n",
        "        tape.watch(time_tensor)\n",
        "\n",
        "        # Reshape your features into the correct format expected by the model\n",
        "        # This could be a single concatenated tensor or a list of tensors\n",
        "        model_input = tf.stack([features['Stock'], features['Strike'], time_tensor,features['Intrest'], features['Divident'], features['Volatility']], axis=-1)\n",
        "\n",
        "        # Run the model on this batch of features to get predictions\n",
        "        predictions = model(model_input, training=True)  # Set training to False if not during training\n",
        "\n",
        "        # Compute the gradient of the predictions with respect to 'Time'\n",
        "        grads = tape.gradient(predictions, time_tensor)\n",
        "        grads_list.append(grads)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "C_yj-zbhGD1i",
        "outputId": "71dc2cdf-0615-4a9a-d44d-db745abd6400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "cannot compute Pack as input #2(zero-based) was expected to be a double tensor but is a float tensor [Op:Pack] name: stack",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-47da578a4e45>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Reshape your features into the correct format expected by the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;31m# This could be a single concatenated tensor or a list of tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mmodel_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Stock'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Strike'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtime_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Intrest'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Divident'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Volatility'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Run the model on this batch of features to get predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   5881\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5882\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5883\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5884\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute Pack as input #2(zero-based) was expected to be a double tensor but is a float tensor [Op:Pack] name: stack"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByVOvwlxzUbh",
        "outputId": "fe27d96d-9fcd-4014-c242-6dde0a1ca51c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               768       \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 1)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 33921 (265.01 KB)\n",
            "Trainable params: 33921 (265.01 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "p_lSqKgQzV7Z",
        "outputId": "017fca22-3db3-46b7-b5c8-ee65804d3221"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"<ipython-input-17-c18ab278d180>\", line 4, in custom_loss  *\n        t.watch(x_tensor)\n\n    ValueError: Passed in object [[1.46421546 0.42758729 0.02569136 0.01189804 0.24322787]\n     [0.93022739 2.7911211  0.01560296 0.02890846 0.07344184]\n     [1.42618641 0.25738741 0.01524909 0.00998639 0.05472978]\n     ...\n     [0.67100654 0.91386802 0.01685517 0.00366419 0.24841322]\n     [0.91249979 0.5830864  0.01691423 0.02982428 0.14258801]\n     [1.36199063 1.73544565 0.01216461 0.00358919 0.24197907]] of type 'ndarray', not tf.Tensor or tf.Variable or ExtensionType.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-88e9704c5111>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_fileo1bn7jwk.py\u001b[0m in \u001b[0;36mtf__custom_loss\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     11\u001b[0m                 \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUndefinedReturnValue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m                     \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mDyDX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\", line 1401, in train_function  *\n        return step_function(self, iterator)\n    File \"<ipython-input-17-c18ab278d180>\", line 4, in custom_loss  *\n        t.watch(x_tensor)\n\n    ValueError: Passed in object [[1.46421546 0.42758729 0.02569136 0.01189804 0.24322787]\n     [0.93022739 2.7911211  0.01560296 0.02890846 0.07344184]\n     [1.42618641 0.25738741 0.01524909 0.00998639 0.05472978]\n     ...\n     [0.67100654 0.91386802 0.01685517 0.00366419 0.24841322]\n     [0.91249979 0.5830864  0.01691423 0.02982428 0.14258801]\n     [1.36199063 1.73544565 0.01216461 0.00358919 0.24197907]] of type 'ndarray', not tf.Tensor or tf.Variable or ExtensionType.\n"
          ]
        }
      ],
      "source": [
        "model.fit(X_train, y_train, epochs = 5, batch_size = 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9LcPB7WzXm0"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAJ-N-q3zanu"
      },
      "outputs": [],
      "source": [
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9Ww2lkhzcCf"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (15,10))\n",
        "plt.scatter((y_test+0.5)*10, (predictions+0.5)*10)\n",
        "plt.axis((0, 10.5, 0, 10.5))\n",
        "plt.xlabel(\"Actual Price\")\n",
        "plt.ylabel(\"Predicted Price\")\n",
        "plt.plot([0,10], [0,10], 'r')\n",
        "plt.grid(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6-oxCV9zd8p"
      },
      "outputs": [],
      "source": [
        "InSamplePredictions = model.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s85XqU7SzfYI"
      },
      "outputs": [],
      "source": [
        "#in sample (80)\n",
        "plt.figure(figsize = (15,10))\n",
        "plt.scatter((y_train+0.5)*10, (InSamplePredictions+0.5)*10)\n",
        "plt.axis((0, 10.5, 0, 10.5))\n",
        "plt.xlabel(\"Actual Price\")\n",
        "plt.ylabel(\"Predicted Price\")\n",
        "plt.plot([0,10], [0,10], 'r')\n",
        "plt.grid(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzERaqbPOnhj"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}